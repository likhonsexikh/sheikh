# Welcome to Sheikh LLM

**Sheikh LLM** is a compact, high-performance language model designed for on-device inference, optimized for structured documents like XML, MDX, and Markdown.

This documentation will guide you through the process of installing, configuring, and using Sheikh LLM in your own projects.

## Key Features

- **Compact Model**: Under 300MB, optimized for ARM and x86 architectures.
- **Structured Document Understanding**: Specializes in XML, MDX, and Markdown.
- **Fast Inference**: Sub-200ms latency per token on mid-tier ARM CPUs.
- **Local Development**: No internet dependency; runs entirely offline.
- **Cross-Platform Support**: Compatible with Linux, macOS, and Windows.

## Getting Started

To get started, check out the following sections:

-   **[Deployment Guide](deployment_guide.md)**: Learn how to deploy Sheikh LLM using Docker or as a standalone binary.
-   **[API Reference](api_reference.md)**: Explore the Sheikh LLM API and SDKs.
-   **[Examples](../examples/)**: See practical examples of how to use the SDKs.

## Community and Support

For bugs, feature requests, or contributions, please visit our [GitHub repository](https://github.com/likhonsexikh/sheikh).
